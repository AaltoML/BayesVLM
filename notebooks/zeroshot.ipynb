{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # add bayesvlm to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.distributions as dists\n",
    "from torchmetrics.classification import MulticlassCalibrationError\n",
    "\n",
    "from bayesvlm.utils import get_model_type_and_size, get_image_size, get_transform, load_model\n",
    "from bayesvlm.data.factory import DataModuleFactory\n",
    "from bayesvlm.hessians import load_hessians, optimize_prior_precision, compute_covariances\n",
    "from bayesvlm.precompute import precompute_text_features, precompute_image_features, make_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction: torch.Tensor, label: torch.Tensor, num_classes: int) -> Tuple[float, float, float]:\n",
    "    ece_metric = MulticlassCalibrationError(num_classes=num_classes, n_bins=20, norm='l1')\n",
    "    one_hot_pred = prediction.argmax(1)\n",
    "    acc = (one_hot_pred == label).float().cpu().numpy()\n",
    "    nlpd = -dists.Categorical(prediction).log_prob(label).cpu().numpy()\n",
    "    ece = ece_metric(prediction, label).item()\n",
    "    return acc, nlpd, ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and dataset\n",
    "model_str = 'clip-base'\n",
    "dataset = 'food101'\n",
    "hessian_dir = '../hessians/hessian_CLIP-ViT-B-32-laion2B-s34B-b79K'\n",
    "pseudo_data_count = 10\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonbaumann/Projects/BayesVLM/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load model and transforms based on `model_str`\n",
    "model_type, model_size = get_model_type_and_size(model_str)\n",
    "transform_image_size = get_image_size(model_str)\n",
    "transform = get_transform(model_type, transform_image_size)\n",
    "image_encoder, text_encoder, vlm = load_model(model_str, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, loss: -3929096.5, lmbda: 1500.0001220703125\n",
      "Epoch 2/300, loss: -3928474.5, lmbda: 1515.07568359375\n",
      "Epoch 3/300, loss: -3927859.5, lmbda: 1530.2978515625\n",
      "Epoch 4/300, loss: -3927250.5, lmbda: 1545.6646728515625\n",
      "Epoch 5/300, loss: -3926650.0, lmbda: 1561.174560546875\n",
      "Epoch 6/300, loss: -3926057.5, lmbda: 1576.8251953125\n",
      "Epoch 7/300, loss: -3925472.25, lmbda: 1592.6143798828125\n",
      "Epoch 8/300, loss: -3924894.5, lmbda: 1608.5386962890625\n",
      "Epoch 9/300, loss: -3924325.75, lmbda: 1624.595947265625\n",
      "Epoch 10/300, loss: -3923765.25, lmbda: 1640.782958984375\n",
      "Epoch 11/300, loss: -3923212.0, lmbda: 1657.096435546875\n",
      "Epoch 12/300, loss: -3922668.0, lmbda: 1673.5330810546875\n",
      "Epoch 13/300, loss: -3922132.5, lmbda: 1690.0892333984375\n",
      "Epoch 14/300, loss: -3921606.0, lmbda: 1706.7611083984375\n",
      "Epoch 15/300, loss: -3921088.5, lmbda: 1723.5447998046875\n",
      "Epoch 16/300, loss: -3920579.5, lmbda: 1740.435546875\n",
      "Epoch 17/300, loss: -3920079.5, lmbda: 1757.4298095703125\n",
      "Epoch 18/300, loss: -3919589.25, lmbda: 1774.5223388671875\n",
      "Epoch 19/300, loss: -3919107.5, lmbda: 1791.709228515625\n",
      "Epoch 20/300, loss: -3918636.0, lmbda: 1808.9849853515625\n",
      "Epoch 21/300, loss: -3918173.5, lmbda: 1826.3446044921875\n",
      "Epoch 22/300, loss: -3917720.0, lmbda: 1843.7828369140625\n",
      "Epoch 23/300, loss: -3917276.75, lmbda: 1861.2935791015625\n",
      "Epoch 24/300, loss: -3916843.25, lmbda: 1878.8719482421875\n",
      "Epoch 25/300, loss: -3916419.5, lmbda: 1896.512451171875\n",
      "Epoch 26/300, loss: -3916004.5, lmbda: 1914.208984375\n",
      "Epoch 27/300, loss: -3915600.0, lmbda: 1931.9554443359375\n",
      "Epoch 28/300, loss: -3915204.75, lmbda: 1949.7457275390625\n",
      "Epoch 29/300, loss: -3914819.0, lmbda: 1967.572998046875\n",
      "Epoch 30/300, loss: -3914444.0, lmbda: 1985.4317626953125\n",
      "Epoch 31/300, loss: -3914077.25, lmbda: 2003.3150634765625\n",
      "Epoch 32/300, loss: -3913722.0, lmbda: 2021.2158203125\n",
      "Epoch 33/300, loss: -3913374.5, lmbda: 2039.126708984375\n",
      "Epoch 34/300, loss: -3913038.0, lmbda: 2057.042236328125\n",
      "Epoch 35/300, loss: -3912710.0, lmbda: 2074.954345703125\n",
      "Epoch 36/300, loss: -3912392.5, lmbda: 2092.856201171875\n",
      "Epoch 37/300, loss: -3912083.0, lmbda: 2110.74072265625\n",
      "Epoch 38/300, loss: -3911784.5, lmbda: 2128.600341796875\n",
      "Epoch 39/300, loss: -3911493.5, lmbda: 2146.427978515625\n",
      "Epoch 40/300, loss: -3911213.75, lmbda: 2164.21484375\n",
      "Epoch 41/300, loss: -3910941.5, lmbda: 2181.95458984375\n",
      "Epoch 42/300, loss: -3910678.25, lmbda: 2199.639404296875\n",
      "Epoch 43/300, loss: -3910425.25, lmbda: 2217.2626953125\n",
      "Epoch 44/300, loss: -3910180.5, lmbda: 2234.814697265625\n",
      "Epoch 45/300, loss: -3909943.5, lmbda: 2252.289794921875\n",
      "Epoch 46/300, loss: -3909716.0, lmbda: 2269.678955078125\n",
      "Epoch 47/300, loss: -3909496.25, lmbda: 2286.97509765625\n",
      "Epoch 48/300, loss: -3909284.75, lmbda: 2304.17041015625\n",
      "Epoch 49/300, loss: -3909081.5, lmbda: 2321.2568359375\n",
      "Epoch 50/300, loss: -3908886.5, lmbda: 2338.22705078125\n",
      "Epoch 51/300, loss: -3908699.5, lmbda: 2355.072998046875\n",
      "Epoch 52/300, loss: -3908520.0, lmbda: 2371.787109375\n",
      "Epoch 53/300, loss: -3908347.75, lmbda: 2388.3623046875\n",
      "Epoch 54/300, loss: -3908183.0, lmbda: 2404.7919921875\n",
      "Epoch 55/300, loss: -3908025.25, lmbda: 2421.06787109375\n",
      "Epoch 56/300, loss: -3907875.0, lmbda: 2437.18212890625\n",
      "Epoch 57/300, loss: -3907730.25, lmbda: 2453.128662109375\n",
      "Epoch 58/300, loss: -3907593.25, lmbda: 2468.900634765625\n",
      "Epoch 59/300, loss: -3907463.0, lmbda: 2484.490478515625\n",
      "Epoch 60/300, loss: -3907337.5, lmbda: 2499.891845703125\n",
      "Epoch 61/300, loss: -3907219.25, lmbda: 2515.098388671875\n",
      "Epoch 62/300, loss: -3907107.0, lmbda: 2530.10400390625\n",
      "Epoch 63/300, loss: -3906999.75, lmbda: 2544.902099609375\n",
      "Epoch 64/300, loss: -3906899.0, lmbda: 2559.486083984375\n",
      "Epoch 65/300, loss: -3906802.0, lmbda: 2573.85205078125\n",
      "Epoch 66/300, loss: -3906711.75, lmbda: 2587.99365234375\n",
      "Epoch 67/300, loss: -3906626.0, lmbda: 2601.905517578125\n",
      "Epoch 68/300, loss: -3906544.5, lmbda: 2615.583984375\n",
      "Epoch 69/300, loss: -3906469.5, lmbda: 2629.0234375\n",
      "Epoch 70/300, loss: -3906396.75, lmbda: 2642.21923828125\n",
      "Epoch 71/300, loss: -3906329.0, lmbda: 2655.16748046875\n",
      "Epoch 72/300, loss: -3906266.0, lmbda: 2667.86376953125\n",
      "Epoch 73/300, loss: -3906206.0, lmbda: 2680.30615234375\n",
      "Epoch 74/300, loss: -3906150.25, lmbda: 2692.49072265625\n",
      "Epoch 75/300, loss: -3906097.5, lmbda: 2704.41357421875\n",
      "Epoch 76/300, loss: -3906048.25, lmbda: 2716.072998046875\n",
      "Epoch 77/300, loss: -3906003.0, lmbda: 2727.468017578125\n",
      "Epoch 78/300, loss: -3905960.5, lmbda: 2738.5947265625\n",
      "Epoch 79/300, loss: -3905921.0, lmbda: 2749.453857421875\n",
      "Epoch 80/300, loss: -3905884.0, lmbda: 2760.042236328125\n",
      "Epoch 81/300, loss: -3905849.5, lmbda: 2770.360107421875\n",
      "Epoch 82/300, loss: -3905818.0, lmbda: 2780.406005859375\n",
      "Epoch 83/300, loss: -3905788.5, lmbda: 2790.1796875\n",
      "Epoch 84/300, loss: -3905760.5, lmbda: 2799.681884765625\n",
      "Epoch 85/300, loss: -3905735.5, lmbda: 2808.91259765625\n",
      "Epoch 86/300, loss: -3905713.25, lmbda: 2817.87255859375\n",
      "Epoch 87/300, loss: -3905691.5, lmbda: 2826.5634765625\n",
      "Epoch 88/300, loss: -3905672.0, lmbda: 2834.986083984375\n",
      "Epoch 89/300, loss: -3905654.25, lmbda: 2843.142578125\n",
      "Epoch 90/300, loss: -3905637.5, lmbda: 2851.034423828125\n",
      "Epoch 91/300, loss: -3905623.0, lmbda: 2858.66455078125\n",
      "Epoch 92/300, loss: -3905608.75, lmbda: 2866.03466796875\n",
      "Epoch 93/300, loss: -3905595.75, lmbda: 2873.14892578125\n",
      "Epoch 94/300, loss: -3905585.25, lmbda: 2880.00830078125\n",
      "Epoch 95/300, loss: -3905574.0, lmbda: 2886.617431640625\n",
      "Epoch 96/300, loss: -3905565.0, lmbda: 2892.9794921875\n",
      "Epoch 97/300, loss: -3905556.5, lmbda: 2899.0986328125\n",
      "Epoch 98/300, loss: -3905549.25, lmbda: 2904.978271484375\n",
      "Epoch 99/300, loss: -3905542.25, lmbda: 2910.623046875\n",
      "Epoch 100/300, loss: -3905536.25, lmbda: 2916.036376953125\n",
      "Epoch 101/300, loss: -3905530.5, lmbda: 2921.223388671875\n",
      "Epoch 102/300, loss: -3905525.5, lmbda: 2926.18798828125\n",
      "Epoch 103/300, loss: -3905521.0, lmbda: 2930.935791015625\n",
      "Epoch 104/300, loss: -3905517.25, lmbda: 2935.4716796875\n",
      "Epoch 105/300, loss: -3905514.0, lmbda: 2939.800048828125\n",
      "Epoch 106/300, loss: -3905511.5, lmbda: 2943.927001953125\n",
      "Epoch 107/300, loss: -3905508.25, lmbda: 2947.857421875\n",
      "Epoch 108/300, loss: -3905506.0, lmbda: 2951.59619140625\n",
      "Epoch 109/300, loss: -3905503.5, lmbda: 2955.147705078125\n",
      "Epoch 110/300, loss: -3905501.75, lmbda: 2958.51904296875\n",
      "Epoch 111/300, loss: -3905499.5, lmbda: 2961.714599609375\n",
      "Epoch 112/300, loss: -3905499.0, lmbda: 2964.73974609375\n",
      "Epoch 113/300, loss: -3905497.25, lmbda: 2967.600830078125\n",
      "Epoch 114/300, loss: -3905496.25, lmbda: 2970.30224609375\n",
      "Epoch 115/300, loss: -3905495.5, lmbda: 2972.849853515625\n",
      "Epoch 116/300, loss: -3905494.5, lmbda: 2975.249267578125\n",
      "Epoch 117/300, loss: -3905493.75, lmbda: 2977.505859375\n",
      "Epoch 118/300, loss: -3905494.0, lmbda: 2979.624755859375\n",
      "Epoch 119/300, loss: -3905493.0, lmbda: 2981.612060546875\n",
      "Epoch 120/300, loss: -3905492.5, lmbda: 2983.47216796875\n",
      "Epoch 121/300, loss: -3905492.0, lmbda: 2985.2080078125\n",
      "Epoch 122/300, loss: -3905492.5, lmbda: 2986.82861328125\n",
      "Epoch 123/300, loss: -3905492.25, lmbda: 2988.335693359375\n",
      "Epoch 124/300, loss: -3905491.5, lmbda: 2989.73828125\n",
      "Epoch 125/300, loss: -3905491.5, lmbda: 2991.035888671875\n",
      "Epoch 126/300, loss: -3905492.0, lmbda: 2992.237060546875\n",
      "Epoch 127/300, loss: -3905491.5, lmbda: 2993.344482421875\n",
      "Epoch 128/300, loss: -3905491.0, lmbda: 2994.363525390625\n",
      "Epoch 129/300, loss: -3905491.5, lmbda: 2995.300537109375\n",
      "Epoch 130/300, loss: -3905491.25, lmbda: 2996.157470703125\n",
      "Epoch 131/300, loss: -3905491.5, lmbda: 2996.937744140625\n",
      "Epoch 132/300, loss: -3905492.0, lmbda: 2997.646728515625\n",
      "Epoch 133/300, loss: -3905490.75, lmbda: 2998.289794921875\n",
      "Epoch 134/300, loss: -3905491.5, lmbda: 2998.870361328125\n",
      "Epoch 135/300, loss: -3905491.0, lmbda: 2999.39111328125\n",
      "Epoch 136/300, loss: -3905491.5, lmbda: 2999.8544921875\n",
      "Epoch 137/300, loss: -3905491.0, lmbda: 3000.263427734375\n",
      "Epoch 138/300, loss: -3905491.5, lmbda: 3000.6240234375\n",
      "Epoch 139/300, loss: -3905491.5, lmbda: 3000.93896484375\n",
      "Epoch 140/300, loss: -3905491.75, lmbda: 3001.210693359375\n",
      "Epoch 141/300, loss: -3905491.5, lmbda: 3001.442626953125\n",
      "Epoch 142/300, loss: -3905491.5, lmbda: 3001.63720703125\n",
      "Epoch 143/300, loss: -3905492.0, lmbda: 3001.797607421875\n",
      "Epoch 144/300, loss: -3905491.75, lmbda: 3001.923583984375\n",
      "Epoch 145/300, loss: -3905491.0, lmbda: 3002.02099609375\n",
      "Epoch 146/300, loss: -3905491.5, lmbda: 3002.092529296875\n",
      "Epoch 147/300, loss: -3905491.5, lmbda: 3002.138427734375\n",
      "Epoch 148/300, loss: -3905491.75, lmbda: 3002.1611328125\n",
      "Epoch 149/300, loss: -3905491.5, lmbda: 3002.1640625\n",
      "Epoch 150/300, loss: -3905492.0, lmbda: 3002.146728515625\n",
      "Epoch 151/300, loss: -3905491.5, lmbda: 3002.112548828125\n",
      "Epoch 152/300, loss: -3905492.0, lmbda: 3002.06396484375\n",
      "Epoch 153/300, loss: -3905491.0, lmbda: 3002.000732421875\n",
      "Epoch 154/300, loss: -3905491.75, lmbda: 3001.926513671875\n",
      "Epoch 155/300, loss: -3905491.5, lmbda: 3001.84033203125\n",
      "Epoch 156/300, loss: -3905492.0, lmbda: 3001.74609375\n",
      "Epoch 157/300, loss: -3905491.75, lmbda: 3001.64306640625\n",
      "Epoch 158/300, loss: -3905492.0, lmbda: 3001.534423828125\n",
      "Epoch 159/300, loss: -3905491.5, lmbda: 3001.419677734375\n",
      "Epoch 160/300, loss: -3905492.0, lmbda: 3001.299560546875\n",
      "Epoch 161/300, loss: -3905491.5, lmbda: 3001.176513671875\n",
      "Epoch 162/300, loss: -3905491.5, lmbda: 3001.050537109375\n",
      "Epoch 163/300, loss: -3905491.5, lmbda: 3000.921875\n",
      "Epoch 164/300, loss: -3905492.0, lmbda: 3000.7900390625\n",
      "Epoch 165/300, loss: -3905492.0, lmbda: 3000.658447265625\n",
      "Epoch 166/300, loss: -3905491.25, lmbda: 3000.52685546875\n",
      "Epoch 167/300, loss: -3905492.0, lmbda: 3000.395263671875\n",
      "Epoch 168/300, loss: -3905491.5, lmbda: 3000.2666015625\n",
      "Epoch 169/300, loss: -3905491.5, lmbda: 3000.137451171875\n",
      "Epoch 170/300, loss: -3905491.0, lmbda: 3000.01171875\n",
      "Epoch 171/300, loss: -3905491.5, lmbda: 2999.888671875\n",
      "Epoch 172/300, loss: -3905491.5, lmbda: 2999.7685546875\n",
      "Epoch 173/300, loss: -3905492.0, lmbda: 2999.6513671875\n",
      "Epoch 174/300, loss: -3905491.75, lmbda: 2999.536865234375\n",
      "Epoch 175/300, loss: -3905491.0, lmbda: 2999.42529296875\n",
      "Epoch 176/300, loss: -3905491.5, lmbda: 2999.316650390625\n",
      "Epoch 177/300, loss: -3905491.0, lmbda: 2999.2109375\n",
      "Epoch 178/300, loss: -3905491.5, lmbda: 2999.11083984375\n",
      "Epoch 179/300, loss: -3905491.0, lmbda: 2999.013427734375\n",
      "Epoch 180/300, loss: -3905491.0, lmbda: 2998.919189453125\n",
      "Epoch 181/300, loss: -3905491.0, lmbda: 2998.83056640625\n",
      "Epoch 182/300, loss: -3905491.0, lmbda: 2998.74462890625\n",
      "Epoch 183/300, loss: -3905491.5, lmbda: 2998.66455078125\n",
      "Epoch 184/300, loss: -3905491.25, lmbda: 2998.58740234375\n",
      "Epoch 185/300, loss: -3905490.5, lmbda: 2998.512939453125\n",
      "Epoch 186/300, loss: -3905491.0, lmbda: 2998.4443359375\n",
      "Epoch 187/300, loss: -3905491.25, lmbda: 2998.37841796875\n",
      "Epoch 188/300, loss: -3905491.25, lmbda: 2998.318603515625\n",
      "Epoch 189/300, loss: -3905491.0, lmbda: 2998.26123046875\n",
      "Epoch 190/300, loss: -3905491.0, lmbda: 2998.20703125\n",
      "Epoch 191/300, loss: -3905491.75, lmbda: 2998.155517578125\n",
      "Epoch 192/300, loss: -3905492.0, lmbda: 2998.109619140625\n",
      "Epoch 193/300, loss: -3905491.25, lmbda: 2998.06689453125\n",
      "Epoch 194/300, loss: -3905491.25, lmbda: 2998.02685546875\n",
      "Epoch 195/300, loss: -3905491.5, lmbda: 2997.98974609375\n",
      "Epoch 196/300, loss: -3905491.0, lmbda: 2997.955322265625\n",
      "Epoch 197/300, loss: -3905491.0, lmbda: 2997.923828125\n",
      "Epoch 198/300, loss: -3905491.0, lmbda: 2997.8955078125\n",
      "Epoch 199/300, loss: -3905491.5, lmbda: 2997.86962890625\n",
      "Epoch 200/300, loss: -3905491.25, lmbda: 2997.8466796875\n",
      "Epoch 201/300, loss: -3905492.0, lmbda: 2997.826904296875\n",
      "Epoch 202/300, loss: -3905491.5, lmbda: 2997.8095703125\n",
      "Epoch 203/300, loss: -3905491.5, lmbda: 2997.79248046875\n",
      "Epoch 204/300, loss: -3905491.5, lmbda: 2997.7783203125\n",
      "Epoch 205/300, loss: -3905491.5, lmbda: 2997.7666015625\n",
      "Epoch 206/300, loss: -3905491.25, lmbda: 2997.755126953125\n",
      "Epoch 207/300, loss: -3905491.5, lmbda: 2997.746826171875\n",
      "Epoch 208/300, loss: -3905492.0, lmbda: 2997.738037109375\n",
      "Epoch 209/300, loss: -3905491.5, lmbda: 2997.732421875\n",
      "Epoch 210/300, loss: -3905491.75, lmbda: 2997.726806640625\n",
      "Epoch 211/300, loss: -3905491.75, lmbda: 2997.723876953125\n",
      "Epoch 212/300, loss: -3905491.5, lmbda: 2997.720947265625\n",
      "Epoch 213/300, loss: -3905491.5, lmbda: 2997.718017578125\n",
      "Epoch 214/300, loss: -3905491.5, lmbda: 2997.718017578125\n",
      "Epoch 215/300, loss: -3905491.5, lmbda: 2997.718017578125\n",
      "Epoch 216/300, loss: -3905491.5, lmbda: 2997.718017578125\n",
      "Epoch 217/300, loss: -3905491.5, lmbda: 2997.720947265625\n",
      "Epoch 218/300, loss: -3905491.75, lmbda: 2997.723876953125\n",
      "Epoch 219/300, loss: -3905491.75, lmbda: 2997.726806640625\n",
      "Epoch 220/300, loss: -3905491.75, lmbda: 2997.7294921875\n",
      "Epoch 221/300, loss: -3905491.5, lmbda: 2997.732421875\n",
      "Epoch 222/300, loss: -3905492.0, lmbda: 2997.735107421875\n",
      "Epoch 223/300, loss: -3905492.0, lmbda: 2997.740966796875\n",
      "Epoch 224/300, loss: -3905491.5, lmbda: 2997.746826171875\n",
      "Epoch 225/300, loss: -3905491.5, lmbda: 2997.75244140625\n",
      "Epoch 226/300, loss: -3905491.0, lmbda: 2997.75830078125\n",
      "Epoch 227/300, loss: -3905491.5, lmbda: 2997.763916015625\n",
      "Epoch 228/300, loss: -3905491.25, lmbda: 2997.76953125\n",
      "Epoch 229/300, loss: -3905491.75, lmbda: 2997.775390625\n",
      "Epoch 230/300, loss: -3905491.5, lmbda: 2997.781005859375\n",
      "Epoch 231/300, loss: -3905491.25, lmbda: 2997.78662109375\n",
      "Epoch 232/300, loss: -3905491.5, lmbda: 2997.79248046875\n",
      "Epoch 233/300, loss: -3905491.5, lmbda: 2997.798095703125\n",
      "Epoch 234/300, loss: -3905491.0, lmbda: 2997.8037109375\n",
      "Epoch 235/300, loss: -3905491.5, lmbda: 2997.8095703125\n",
      "Epoch 236/300, loss: -3905491.75, lmbda: 2997.8154296875\n",
      "Epoch 237/300, loss: -3905491.5, lmbda: 2997.821044921875\n",
      "Epoch 238/300, loss: -3905492.0, lmbda: 2997.826904296875\n",
      "Epoch 239/300, loss: -3905491.75, lmbda: 2997.82958984375\n",
      "Epoch 240/300, loss: -3905491.75, lmbda: 2997.83251953125\n",
      "Epoch 241/300, loss: -3905491.5, lmbda: 2997.835205078125\n",
      "Epoch 242/300, loss: -3905491.5, lmbda: 2997.838134765625\n",
      "Epoch 243/300, loss: -3905491.5, lmbda: 2997.8408203125\n",
      "Epoch 244/300, loss: -3905491.5, lmbda: 2997.843994140625\n",
      "Epoch 245/300, loss: -3905491.25, lmbda: 2997.8466796875\n",
      "Epoch 246/300, loss: -3905491.5, lmbda: 2997.849609375\n",
      "Epoch 247/300, loss: -3905491.5, lmbda: 2997.8525390625\n",
      "Epoch 248/300, loss: -3905491.5, lmbda: 2997.855224609375\n",
      "Epoch 249/300, loss: -3905491.5, lmbda: 2997.858154296875\n",
      "Epoch 250/300, loss: -3905491.5, lmbda: 2997.861083984375\n",
      "Epoch 251/300, loss: -3905491.5, lmbda: 2997.864013671875\n",
      "Epoch 252/300, loss: -3905491.5, lmbda: 2997.86669921875\n",
      "Epoch 253/300, loss: -3905491.5, lmbda: 2997.86962890625\n",
      "Epoch 254/300, loss: -3905491.25, lmbda: 2997.872314453125\n",
      "Epoch 255/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 256/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 257/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 258/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 259/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 260/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 261/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 262/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 263/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 264/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 265/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 266/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 267/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 268/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 269/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 270/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 271/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 272/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 273/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 274/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 275/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 276/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 277/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 278/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 279/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 280/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 281/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 282/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 283/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 284/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 285/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 286/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 287/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 288/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 289/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 290/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 291/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 292/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 293/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 294/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 295/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 296/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 297/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 298/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 299/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 300/300, loss: -3905491.25, lmbda: 2997.87548828125\n",
      "Epoch 1/300, loss: -2149382.5, lmbda: 1500.0001220703125\n",
      "Epoch 2/300, loss: -2149079.0, lmbda: 1515.07568359375\n",
      "Epoch 3/300, loss: -2148780.25, lmbda: 1530.2955322265625\n",
      "Epoch 4/300, loss: -2148487.0, lmbda: 1545.656494140625\n",
      "Epoch 5/300, loss: -2148198.5, lmbda: 1561.1552734375\n",
      "Epoch 6/300, loss: -2147915.5, lmbda: 1576.7867431640625\n",
      "Epoch 7/300, loss: -2147637.75, lmbda: 1592.547607421875\n",
      "Epoch 8/300, loss: -2147365.75, lmbda: 1608.43212890625\n",
      "Epoch 9/300, loss: -2147099.25, lmbda: 1624.435546875\n",
      "Epoch 10/300, loss: -2146838.5, lmbda: 1640.552978515625\n",
      "Epoch 11/300, loss: -2146583.25, lmbda: 1656.7772216796875\n",
      "Epoch 12/300, loss: -2146334.5, lmbda: 1673.10302734375\n",
      "Epoch 13/300, loss: -2146091.0, lmbda: 1689.5235595703125\n",
      "Epoch 14/300, loss: -2145854.0, lmbda: 1706.031982421875\n",
      "Epoch 15/300, loss: -2145622.5, lmbda: 1722.621337890625\n",
      "Epoch 16/300, loss: -2145398.0, lmbda: 1739.283203125\n",
      "Epoch 17/300, loss: -2145179.0, lmbda: 1756.0108642578125\n",
      "Epoch 18/300, loss: -2144966.25, lmbda: 1772.7952880859375\n",
      "Epoch 19/300, loss: -2144759.5, lmbda: 1789.6275634765625\n",
      "Epoch 20/300, loss: -2144559.5, lmbda: 1806.499755859375\n",
      "Epoch 21/300, loss: -2144365.5, lmbda: 1823.4017333984375\n",
      "Epoch 22/300, loss: -2144178.0, lmbda: 1840.3248291015625\n",
      "Epoch 23/300, loss: -2143996.75, lmbda: 1857.2586669921875\n",
      "Epoch 24/300, loss: -2143821.5, lmbda: 1874.1939697265625\n",
      "Epoch 25/300, loss: -2143652.5, lmbda: 1891.120361328125\n",
      "Epoch 26/300, loss: -2143490.0, lmbda: 1908.02685546875\n",
      "Epoch 27/300, loss: -2143333.0, lmbda: 1924.902587890625\n",
      "Epoch 28/300, loss: -2143182.5, lmbda: 1941.7369384765625\n",
      "Epoch 29/300, loss: -2143038.0, lmbda: 1958.5185546875\n",
      "Epoch 30/300, loss: -2142900.0, lmbda: 1975.2371826171875\n",
      "Epoch 31/300, loss: -2142767.5, lmbda: 1991.8798828125\n",
      "Epoch 32/300, loss: -2142640.5, lmbda: 2008.43603515625\n",
      "Epoch 33/300, loss: -2142519.5, lmbda: 2024.89306640625\n",
      "Epoch 34/300, loss: -2142404.25, lmbda: 2041.2406005859375\n",
      "Epoch 35/300, loss: -2142294.5, lmbda: 2057.466064453125\n",
      "Epoch 36/300, loss: -2142189.75, lmbda: 2073.5576171875\n",
      "Epoch 37/300, loss: -2142091.0, lmbda: 2089.503662109375\n",
      "Epoch 38/300, loss: -2141997.0, lmbda: 2105.292724609375\n",
      "Epoch 39/300, loss: -2141908.25, lmbda: 2120.91259765625\n",
      "Epoch 40/300, loss: -2141824.25, lmbda: 2136.3515625\n",
      "Epoch 41/300, loss: -2141745.0, lmbda: 2151.5986328125\n",
      "Epoch 42/300, loss: -2141670.5, lmbda: 2166.642333984375\n",
      "Epoch 43/300, loss: -2141601.0, lmbda: 2181.471923828125\n",
      "Epoch 44/300, loss: -2141535.25, lmbda: 2196.0771484375\n",
      "Epoch 45/300, loss: -2141473.5, lmbda: 2210.447021484375\n",
      "Epoch 46/300, loss: -2141416.25, lmbda: 2224.57177734375\n",
      "Epoch 47/300, loss: -2141362.75, lmbda: 2238.440673828125\n",
      "Epoch 48/300, loss: -2141312.5, lmbda: 2252.044921875\n",
      "Epoch 49/300, loss: -2141266.5, lmbda: 2265.37548828125\n",
      "Epoch 50/300, loss: -2141223.75, lmbda: 2278.424072265625\n",
      "Epoch 51/300, loss: -2141184.0, lmbda: 2291.181884765625\n",
      "Epoch 52/300, loss: -2141147.5, lmbda: 2303.641845703125\n",
      "Epoch 53/300, loss: -2141114.0, lmbda: 2315.797607421875\n",
      "Epoch 54/300, loss: -2141083.0, lmbda: 2327.642333984375\n",
      "Epoch 55/300, loss: -2141055.0, lmbda: 2339.16943359375\n",
      "Epoch 56/300, loss: -2141029.0, lmbda: 2350.37451171875\n",
      "Epoch 57/300, loss: -2141005.5, lmbda: 2361.253173828125\n",
      "Epoch 58/300, loss: -2140984.0, lmbda: 2371.800537109375\n",
      "Epoch 59/300, loss: -2140965.0, lmbda: 2382.013671875\n",
      "Epoch 60/300, loss: -2140947.5, lmbda: 2391.890869140625\n",
      "Epoch 61/300, loss: -2140931.75, lmbda: 2401.4287109375\n",
      "Epoch 62/300, loss: -2140917.5, lmbda: 2410.62646484375\n",
      "Epoch 63/300, loss: -2140905.25, lmbda: 2419.484619140625\n",
      "Epoch 64/300, loss: -2140894.0, lmbda: 2428.00244140625\n",
      "Epoch 65/300, loss: -2140884.0, lmbda: 2436.1806640625\n",
      "Epoch 66/300, loss: -2140875.5, lmbda: 2444.020263671875\n",
      "Epoch 67/300, loss: -2140867.75, lmbda: 2451.524169921875\n",
      "Epoch 68/300, loss: -2140861.0, lmbda: 2458.69482421875\n",
      "Epoch 69/300, loss: -2140855.0, lmbda: 2465.53466796875\n",
      "Epoch 70/300, loss: -2140849.75, lmbda: 2472.048095703125\n",
      "Epoch 71/300, loss: -2140845.25, lmbda: 2478.23974609375\n",
      "Epoch 72/300, loss: -2140842.0, lmbda: 2484.114013671875\n",
      "Epoch 73/300, loss: -2140838.5, lmbda: 2489.676513671875\n",
      "Epoch 74/300, loss: -2140836.0, lmbda: 2494.934326171875\n",
      "Epoch 75/300, loss: -2140833.5, lmbda: 2499.89306640625\n",
      "Epoch 76/300, loss: -2140832.0, lmbda: 2504.559326171875\n",
      "Epoch 77/300, loss: -2140830.0, lmbda: 2508.94140625\n",
      "Epoch 78/300, loss: -2140829.25, lmbda: 2513.0458984375\n",
      "Epoch 79/300, loss: -2140828.25, lmbda: 2516.881103515625\n",
      "Epoch 80/300, loss: -2140827.5, lmbda: 2520.4541015625\n",
      "Epoch 81/300, loss: -2140827.0, lmbda: 2523.7744140625\n",
      "Epoch 82/300, loss: -2140826.5, lmbda: 2526.85107421875\n",
      "Epoch 83/300, loss: -2140826.0, lmbda: 2529.69140625\n",
      "Epoch 84/300, loss: -2140825.75, lmbda: 2532.305419921875\n",
      "Epoch 85/300, loss: -2140825.75, lmbda: 2534.7021484375\n",
      "Epoch 86/300, loss: -2140825.75, lmbda: 2536.8896484375\n",
      "Epoch 87/300, loss: -2140825.75, lmbda: 2538.8779296875\n",
      "Epoch 88/300, loss: -2140825.5, lmbda: 2540.675048828125\n",
      "Epoch 89/300, loss: -2140826.0, lmbda: 2542.291748046875\n",
      "Epoch 90/300, loss: -2140826.0, lmbda: 2543.736083984375\n",
      "Epoch 91/300, loss: -2140826.0, lmbda: 2545.01708984375\n",
      "Epoch 92/300, loss: -2140826.0, lmbda: 2546.1435546875\n",
      "Epoch 93/300, loss: -2140826.0, lmbda: 2547.124755859375\n",
      "Epoch 94/300, loss: -2140826.0, lmbda: 2547.96923828125\n",
      "Epoch 95/300, loss: -2140826.0, lmbda: 2548.684814453125\n",
      "Epoch 96/300, loss: -2140826.5, lmbda: 2549.280517578125\n",
      "Epoch 97/300, loss: -2140826.5, lmbda: 2549.764404296875\n",
      "Epoch 98/300, loss: -2140827.0, lmbda: 2550.1435546875\n",
      "Epoch 99/300, loss: -2140826.25, lmbda: 2550.427001953125\n",
      "Epoch 100/300, loss: -2140826.5, lmbda: 2550.620361328125\n",
      "Epoch 101/300, loss: -2140826.5, lmbda: 2550.732177734375\n",
      "Epoch 102/300, loss: -2140826.5, lmbda: 2550.7685546875\n",
      "Epoch 103/300, loss: -2140826.5, lmbda: 2550.737060546875\n",
      "Epoch 104/300, loss: -2140826.75, lmbda: 2550.643310546875\n",
      "Epoch 105/300, loss: -2140826.25, lmbda: 2550.493896484375\n",
      "Epoch 106/300, loss: -2140826.5, lmbda: 2550.293212890625\n",
      "Epoch 107/300, loss: -2140826.25, lmbda: 2550.048828125\n",
      "Epoch 108/300, loss: -2140826.5, lmbda: 2549.764404296875\n",
      "Epoch 109/300, loss: -2140826.0, lmbda: 2549.44580078125\n",
      "Epoch 110/300, loss: -2140826.0, lmbda: 2549.096923828125\n",
      "Epoch 111/300, loss: -2140826.5, lmbda: 2548.722412109375\n",
      "Epoch 112/300, loss: -2140826.5, lmbda: 2548.32763671875\n",
      "Epoch 113/300, loss: -2140826.25, lmbda: 2547.91552734375\n",
      "Epoch 114/300, loss: -2140826.0, lmbda: 2547.490478515625\n",
      "Epoch 115/300, loss: -2140826.25, lmbda: 2547.05419921875\n",
      "Epoch 116/300, loss: -2140826.25, lmbda: 2546.611083984375\n",
      "Epoch 117/300, loss: -2140826.25, lmbda: 2546.164306640625\n",
      "Epoch 118/300, loss: -2140826.0, lmbda: 2545.71630859375\n",
      "Epoch 119/300, loss: -2140826.0, lmbda: 2545.2685546875\n",
      "Epoch 120/300, loss: -2140826.0, lmbda: 2544.824462890625\n",
      "Epoch 121/300, loss: -2140826.0, lmbda: 2544.38525390625\n",
      "Epoch 122/300, loss: -2140825.75, lmbda: 2543.953125\n",
      "Epoch 123/300, loss: -2140826.0, lmbda: 2543.52978515625\n",
      "Epoch 124/300, loss: -2140825.75, lmbda: 2543.1162109375\n",
      "Epoch 125/300, loss: -2140825.5, lmbda: 2542.7138671875\n",
      "Epoch 126/300, loss: -2140825.75, lmbda: 2542.32470703125\n",
      "Epoch 127/300, loss: -2140825.5, lmbda: 2541.94873046875\n",
      "Epoch 128/300, loss: -2140825.75, lmbda: 2541.58642578125\n",
      "Epoch 129/300, loss: -2140825.5, lmbda: 2541.238525390625\n",
      "Epoch 130/300, loss: -2140826.0, lmbda: 2540.906494140625\n",
      "Epoch 131/300, loss: -2140825.5, lmbda: 2540.59033203125\n",
      "Epoch 132/300, loss: -2140825.5, lmbda: 2540.2900390625\n",
      "Epoch 133/300, loss: -2140826.0, lmbda: 2540.00537109375\n",
      "Epoch 134/300, loss: -2140825.5, lmbda: 2539.737548828125\n",
      "Epoch 135/300, loss: -2140825.75, lmbda: 2539.48583984375\n",
      "Epoch 136/300, loss: -2140825.5, lmbda: 2539.24951171875\n",
      "Epoch 137/300, loss: -2140825.75, lmbda: 2539.029296875\n",
      "Epoch 138/300, loss: -2140825.75, lmbda: 2538.82470703125\n",
      "Epoch 139/300, loss: -2140825.5, lmbda: 2538.6357421875\n",
      "Epoch 140/300, loss: -2140825.5, lmbda: 2538.461669921875\n",
      "Epoch 141/300, loss: -2140825.5, lmbda: 2538.302001953125\n",
      "Epoch 142/300, loss: -2140826.0, lmbda: 2538.15673828125\n",
      "Epoch 143/300, loss: -2140825.75, lmbda: 2538.024658203125\n",
      "Epoch 144/300, loss: -2140825.5, lmbda: 2537.906005859375\n",
      "Epoch 145/300, loss: -2140825.5, lmbda: 2537.80078125\n",
      "Epoch 146/300, loss: -2140825.5, lmbda: 2537.70751953125\n",
      "Epoch 147/300, loss: -2140825.75, lmbda: 2537.625244140625\n",
      "Epoch 148/300, loss: -2140826.0, lmbda: 2537.553955078125\n",
      "Epoch 149/300, loss: -2140825.75, lmbda: 2537.49365234375\n",
      "Epoch 150/300, loss: -2140825.5, lmbda: 2537.4423828125\n",
      "Epoch 151/300, loss: -2140825.5, lmbda: 2537.400390625\n",
      "Epoch 152/300, loss: -2140825.5, lmbda: 2537.3662109375\n",
      "Epoch 153/300, loss: -2140825.5, lmbda: 2537.3408203125\n",
      "Epoch 154/300, loss: -2140825.5, lmbda: 2537.322998046875\n",
      "Epoch 155/300, loss: -2140825.5, lmbda: 2537.310791015625\n",
      "Epoch 156/300, loss: -2140825.5, lmbda: 2537.3046875\n",
      "Epoch 157/300, loss: -2140825.5, lmbda: 2537.3046875\n",
      "Epoch 158/300, loss: -2140825.5, lmbda: 2537.3095703125\n",
      "Epoch 159/300, loss: -2140825.5, lmbda: 2537.319091796875\n",
      "Epoch 160/300, loss: -2140825.75, lmbda: 2537.33251953125\n",
      "Epoch 161/300, loss: -2140825.75, lmbda: 2537.349609375\n",
      "Epoch 162/300, loss: -2140825.75, lmbda: 2537.3701171875\n",
      "Epoch 163/300, loss: -2140825.75, lmbda: 2537.392822265625\n",
      "Epoch 164/300, loss: -2140825.5, lmbda: 2537.41845703125\n",
      "Epoch 165/300, loss: -2140825.75, lmbda: 2537.4462890625\n",
      "Epoch 166/300, loss: -2140825.75, lmbda: 2537.475341796875\n",
      "Epoch 167/300, loss: -2140826.0, lmbda: 2537.50537109375\n",
      "Epoch 168/300, loss: -2140826.0, lmbda: 2537.536865234375\n",
      "Epoch 169/300, loss: -2140826.0, lmbda: 2537.56982421875\n",
      "Epoch 170/300, loss: -2140825.5, lmbda: 2537.602294921875\n",
      "Epoch 171/300, loss: -2140825.75, lmbda: 2537.634765625\n",
      "Epoch 172/300, loss: -2140825.75, lmbda: 2537.667724609375\n",
      "Epoch 173/300, loss: -2140825.5, lmbda: 2537.700439453125\n",
      "Epoch 174/300, loss: -2140825.5, lmbda: 2537.731689453125\n",
      "Epoch 175/300, loss: -2140825.5, lmbda: 2537.763427734375\n",
      "Epoch 176/300, loss: -2140825.5, lmbda: 2537.79345703125\n",
      "Epoch 177/300, loss: -2140825.75, lmbda: 2537.822509765625\n",
      "Epoch 178/300, loss: -2140825.75, lmbda: 2537.8515625\n",
      "Epoch 179/300, loss: -2140825.75, lmbda: 2537.87939453125\n",
      "Epoch 180/300, loss: -2140825.5, lmbda: 2537.906005859375\n",
      "Epoch 181/300, loss: -2140826.0, lmbda: 2537.931396484375\n",
      "Epoch 182/300, loss: -2140825.5, lmbda: 2537.95556640625\n",
      "Epoch 183/300, loss: -2140825.5, lmbda: 2537.978515625\n",
      "Epoch 184/300, loss: -2140825.75, lmbda: 2537.999267578125\n",
      "Epoch 185/300, loss: -2140825.75, lmbda: 2538.0185546875\n",
      "Epoch 186/300, loss: -2140826.0, lmbda: 2538.036865234375\n",
      "Epoch 187/300, loss: -2140825.5, lmbda: 2538.053466796875\n",
      "Epoch 188/300, loss: -2140825.5, lmbda: 2538.0693359375\n",
      "Epoch 189/300, loss: -2140825.75, lmbda: 2538.083984375\n",
      "Epoch 190/300, loss: -2140825.75, lmbda: 2538.09716796875\n",
      "Epoch 191/300, loss: -2140825.75, lmbda: 2538.109375\n",
      "Epoch 192/300, loss: -2140825.5, lmbda: 2538.1201171875\n",
      "Epoch 193/300, loss: -2140825.75, lmbda: 2538.130126953125\n",
      "Epoch 194/300, loss: -2140825.5, lmbda: 2538.138427734375\n",
      "Epoch 195/300, loss: -2140825.75, lmbda: 2538.1455078125\n",
      "Epoch 196/300, loss: -2140825.5, lmbda: 2538.151611328125\n",
      "Epoch 197/300, loss: -2140826.0, lmbda: 2538.15673828125\n",
      "Epoch 198/300, loss: -2140826.0, lmbda: 2538.16015625\n",
      "Epoch 199/300, loss: -2140825.75, lmbda: 2538.163818359375\n",
      "Epoch 200/300, loss: -2140825.75, lmbda: 2538.166259765625\n",
      "Epoch 201/300, loss: -2140825.5, lmbda: 2538.16748046875\n",
      "Epoch 202/300, loss: -2140825.5, lmbda: 2538.168701171875\n",
      "Epoch 203/300, loss: -2140825.5, lmbda: 2538.168701171875\n",
      "Epoch 204/300, loss: -2140825.5, lmbda: 2538.168701171875\n",
      "Epoch 205/300, loss: -2140825.5, lmbda: 2538.16748046875\n",
      "Epoch 206/300, loss: -2140825.75, lmbda: 2538.166259765625\n",
      "Epoch 207/300, loss: -2140825.75, lmbda: 2538.1650390625\n",
      "Epoch 208/300, loss: -2140825.75, lmbda: 2538.16259765625\n",
      "Epoch 209/300, loss: -2140826.0, lmbda: 2538.16015625\n",
      "Epoch 210/300, loss: -2140826.0, lmbda: 2538.157958984375\n",
      "Epoch 211/300, loss: -2140825.75, lmbda: 2538.155517578125\n",
      "Epoch 212/300, loss: -2140825.5, lmbda: 2538.15283203125\n",
      "Epoch 213/300, loss: -2140825.5, lmbda: 2538.150390625\n",
      "Epoch 214/300, loss: -2140825.75, lmbda: 2538.146728515625\n",
      "Epoch 215/300, loss: -2140826.0, lmbda: 2538.143310546875\n",
      "Epoch 216/300, loss: -2140825.5, lmbda: 2538.1396484375\n",
      "Epoch 217/300, loss: -2140825.5, lmbda: 2538.135986328125\n",
      "Epoch 218/300, loss: -2140825.75, lmbda: 2538.13232421875\n",
      "Epoch 219/300, loss: -2140825.75, lmbda: 2538.128662109375\n",
      "Epoch 220/300, loss: -2140825.5, lmbda: 2538.125\n",
      "Epoch 221/300, loss: -2140825.5, lmbda: 2538.12255859375\n",
      "Epoch 222/300, loss: -2140825.5, lmbda: 2538.1201171875\n",
      "Epoch 223/300, loss: -2140825.5, lmbda: 2538.11767578125\n",
      "Epoch 224/300, loss: -2140825.75, lmbda: 2538.115478515625\n",
      "Epoch 225/300, loss: -2140825.75, lmbda: 2538.113037109375\n",
      "Epoch 226/300, loss: -2140825.5, lmbda: 2538.110595703125\n",
      "Epoch 227/300, loss: -2140825.5, lmbda: 2538.108154296875\n",
      "Epoch 228/300, loss: -2140825.5, lmbda: 2538.105712890625\n",
      "Epoch 229/300, loss: -2140825.5, lmbda: 2538.103271484375\n",
      "Epoch 230/300, loss: -2140825.75, lmbda: 2538.100830078125\n",
      "Epoch 231/300, loss: -2140825.75, lmbda: 2538.099609375\n",
      "Epoch 232/300, loss: -2140825.75, lmbda: 2538.098388671875\n",
      "Epoch 233/300, loss: -2140825.75, lmbda: 2538.09716796875\n",
      "Epoch 234/300, loss: -2140825.5, lmbda: 2538.095947265625\n",
      "Epoch 235/300, loss: -2140825.5, lmbda: 2538.0947265625\n",
      "Epoch 236/300, loss: -2140825.5, lmbda: 2538.093505859375\n",
      "Epoch 237/300, loss: -2140825.5, lmbda: 2538.09228515625\n",
      "Epoch 238/300, loss: -2140825.5, lmbda: 2538.091064453125\n",
      "Epoch 239/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 240/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 241/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 242/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 243/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 244/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 245/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 246/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 247/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 248/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 249/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 250/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 251/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 252/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 253/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 254/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 255/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 256/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 257/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 258/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 259/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 260/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 261/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 262/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 263/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 264/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 265/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 266/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 267/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 268/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 269/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 270/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 271/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 272/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 273/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 274/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 275/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 276/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 277/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 278/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 279/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 280/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 281/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 282/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 283/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 284/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 285/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 286/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 287/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 288/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 289/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 290/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 291/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 292/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 293/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 294/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 295/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 296/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 297/300, loss: -2140825.5, lmbda: 2538.090087890625\n",
      "Epoch 298/300, loss: -2140825.5, lmbda: 2538.091064453125\n",
      "Epoch 299/300, loss: -2140825.5, lmbda: 2538.091064453125\n",
      "Epoch 300/300, loss: -2140825.5, lmbda: 2538.091064453125\n",
      "n_img: 10\n",
      "n_txt: 10\n",
      "lambda_img: 2997.87548828125\n",
      "lambda_txt: 2538.091064453125\n"
     ]
    }
   ],
   "source": [
    "# load hessians\n",
    "info = {'n_img': pseudo_data_count, 'n_txt': pseudo_data_count}\n",
    "A_img, B_img = load_hessians(hessian_dir, tag='img', return_info=False)\n",
    "A_txt, B_txt = load_hessians(hessian_dir, tag='txt', return_info=False)\n",
    "\n",
    "# optimize prior precision based on marginal log-likelihood\n",
    "info['lambda_img'] = optimize_prior_precision(\n",
    "    image_encoder.vision_projection,\n",
    "    A=A_img,\n",
    "    B=B_img,\n",
    "    lmbda_init=1500,\n",
    "    n=info['n_img'],\n",
    "    lr=1e-2,\n",
    "    num_steps=300,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ").item()\n",
    "\n",
    "info['lambda_txt'] = optimize_prior_precision(\n",
    "    text_encoder.text_projection,\n",
    "    A=A_txt,\n",
    "    B=B_txt,\n",
    "    lmbda_init=1500,\n",
    "    n=info['n_txt'],\n",
    "    lr=1e-2,\n",
    "    num_steps=300,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ").item()\n",
    "\n",
    "print(\"n_img:\", info['n_img'])\n",
    "print(\"n_txt:\", info['n_txt'])\n",
    "print(\"lambda_img:\", info['lambda_img'])\n",
    "print(\"lambda_txt:\", info['lambda_txt'])\n",
    "\n",
    "# pass the covatiances to the model\n",
    "cov_img, cov_txt = compute_covariances(A_img, B_img, A_txt, B_txt, info)\n",
    "vlm.set_covariances(cov_img, cov_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data module\n",
    "f = DataModuleFactory(\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    train_transform=transform,\n",
    "    test_transform=transform,\n",
    "    shuffle_train=True,\n",
    ")\n",
    "dm = f.create(dataset)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [03:53<00:00,  3.39it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# precompute embeddings\n",
    "with torch.no_grad():\n",
    "    image_outputs_test, image_class_ids_test, image_ids_test = precompute_image_features(\n",
    "        image_encoder=image_encoder,\n",
    "        loader=dm.test_dataloader(),\n",
    "    )\n",
    "\n",
    "    label_outputs = precompute_text_features(\n",
    "        text_encoder=text_encoder,\n",
    "        class_prompts=dm.class_prompts,\n",
    "        batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/790 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 790/790 [00:04<00:00, 162.43it/s]\n",
      "  0%|          | 0/790 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 790/790 [00:03<00:00, 250.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# make predictions for vanilla BayesVLM and vanilla CLIP (MAP estimate)\n",
    "logits_bayesvlm = make_predictions(\n",
    "    clip=vlm,\n",
    "    image_outputs=image_outputs_test,\n",
    "    text_outputs=label_outputs,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    map_estimate=False,\n",
    ")\n",
    "\n",
    "logits_map = make_predictions(\n",
    "    clip=vlm,\n",
    "    image_outputs=image_outputs_test,\n",
    "    text_outputs=label_outputs,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    map_estimate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilistic logits to probabilities\n",
    "kappa = 1 / torch.sqrt(1. + torch.pi / 8 * logits_bayesvlm.var)\n",
    "probas_bayesvlm = torch.softmax(kappa * logits_bayesvlm.mean, dim=-1)\n",
    "\n",
    "# convert MAP logits to probabilities\n",
    "probas_map = torch.softmax(logits_map.mean, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the predictions\n",
    "acc_bayesvlm, nlpd_bayesvlm, ece_bayesvlm = evaluate_prediction(\n",
    "    prediction=probas_bayesvlm, \n",
    "    label=image_class_ids_test, \n",
    "    num_classes=len(dm.class_prompts),\n",
    ")\n",
    "\n",
    "acc_map, nlpd_map, ece_map = evaluate_prediction(\n",
    "    prediction=probas_map,\n",
    "    label=image_class_ids_test,\n",
    "    num_classes=len(dm.class_prompts),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BayesVLM  MAP       \n",
      "acc       0.8032    0.8008    \n",
      "nlpd      0.6808    0.7053    \n",
      "ece       0.0083    0.0387    \n"
     ]
    }
   ],
   "source": [
    "# table with zero shot results \n",
    "print(f\"{'':<10}{'BayesVLM':<10}{'MAP':<10}\")\n",
    "print(f\"{'acc':<10}{acc_bayesvlm.mean():<10.4f}{acc_map.mean():<10.4f}\")\n",
    "print(f\"{'nlpd':<10}{nlpd_bayesvlm.mean():<10.4f}{nlpd_map.mean():<10.4f}\")\n",
    "print(f\"{'ece':<10}{ece_bayesvlm:<10.4f}{ece_map:<10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
